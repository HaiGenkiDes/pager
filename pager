#!/usr/bin/env python

#stdlib imports
import argparse
import configparser
import os.path
import sys
import pprint
import locale
import json
import logging
import re
import glob
import traceback
import io

#third party imports
import pandas as pd
import numpy as np
from mapio.shake import getHeaderData
import yaml

#local imports
from losspager.models.exposure import Exposure
from losspager.models.econexposure import EconExposure
from losspager.models.emploss import EmpiricalLoss
from losspager.models.semimodel import SemiEmpiricalFatality
from losspager.models.growth import PopulationGrowth
from losspager.utils.country import Country
from losspager.utils.logger import PagerLogger
from losspager.onepager.comment import get_impact_comments
from losspager.onepager.comment import get_structure_comment
from losspager.onepager.comment import get_secondary_comment
from losspager.onepager.comment import get_historical_comment
from losspager.io.pagerdata import PagerData
from losspager.vis.impactscale import drawImpactScale
from losspager.vis.contourmap2 import draw_contour

COUNTRY = Country()
TIMEFMT = '%Y-%m-%d %H:%M:%S'

def read_config(configfile):
    """Read in configuration parameters from config .py file.
    
    """
    config = yaml.load(open(configfile,'rt'))
    return config

def _get_pop_year(event_year,popyears):
    pop_year = None
    tmin = 10000000
    popfile = None
    for popdict in popyears:
        popyear = popdict['population_year']
        popgrid = popdict['population_grid']
        if not os.path.isfile(popgrid):
            print('Population grid file %s does not exist.' % popgrid)
            sys.exit(1)
        if abs(popyear-event_year) < tmin:
            tmin = abs(popyear-event_year)
            pop_year = popyear
            popfile = popgrid
    return (pop_year,popfile)

def get_pager_version(eventfolder):
    pager_version = 1
    if not os.path.isdir(eventfolder):
        os.makedirs(eventfolder)
        last_version = 0
    else:
        allfolders = glob.glob(os.path.join(eventfolder,'version.*'))
        allfolders.sort()
        if len(allfolders):
            base,last_folder = os.path.split(allfolders[-1])
            last_version = int(re.findall('\d+',last_folder)[0])
        else:
            last_version = 0
    return last_version + 1

def _draw_probs(fatmodel,fatdict,ecomodel,ecodict,version_folder):
    fatG = fatmodel.getCombinedG(fatdict)
    fat_probs = fatmodel.getProbabilities(fatdict,fatG)
    fat_figure = drawImpactScale(fat_probs,'fatality')

    ecoG = ecomodel.getCombinedG(ecodict)
    eco_probs = ecomodel.getProbabilities(ecodict,ecoG)
    eco_figure = drawImpactScale(eco_probs,'economic')

    fat_probs_file = os.path.join(version_folder,'alertfatal.pdf')
    eco_probs_file = os.path.join(version_folder,'alertecon.pdf')
    fat_figure.savefig(fat_probs_file,bbox_inches='tight')
    eco_figure.savefig(eco_probs_file,bbox_inches='tight')
    return (fat_probs_file,eco_probs_file)

def main(pargs,config):
    #get the users home directory
    homedir = os.path.expanduser('~')
    script_dir = os.path.dirname(os.path.abspath(__file__)) #where is this script?
    
    #Make sure grid.xml file exists
    if not os.path.isfile(pargs.gridfile):
        print('ShakeMap Grid file %s does not exist.' % pargs.gridfile)
        sys.exit(1)

    pager_folder = os.path.join(homedir,config['output_folder'])
    plog = None
    if not pargs.debug:
        #stdout will now be logged as INFO, stderr will be logged as WARNING
        mail_host = config['mail_host']
        mail_from = config['mail_from']
        plog = PagerLogger(pager_folder,redirect=True,
                           from_address=mail_from,
                           mail_host=mail_host)
        
        plog.addEmailHandler(config['developers']) #failover email alert system

    try:
        #get all the basic event information and print it, if requested
        shake_tuple = getHeaderData(pargs.gridfile)
        #TODO - older shakemaps do not include network in event ID - account for this!
        eid = shake_tuple[1]['event_id']

        #create the event directory (if it does not exist), and start logging there
        event_folder = os.path.join(pager_folder,eid)
        pager_version = get_pager_version(event_folder)
        version_folder = os.path.join(event_folder,'version.%03d' % pager_version)
        os.makedirs(version_folder)
        event_logfile = os.path.join(version_folder,'event.log')
        if plog is not None:
            plog.switchToEventFileHandler(event_logfile)

        #get the rest of the event info
        etime = shake_tuple[1]['event_timestamp']
        elat = shake_tuple[1]['lat']
        elon = shake_tuple[1]['lon']
        edepth = shake_tuple[1]['depth']
        emag = shake_tuple[1]['magnitude']
        location = shake_tuple[1]['event_description']

        #get the year of the event
        event_year = shake_tuple[1]['event_timestamp'].year

        #find the population data collected most closely to the event_year
        pop_year,popfile = _get_pop_year(event_year,config['model_data']['population_data'])

        print('Population year: %i Population file: %s\n' % (pop_year,popfile))

        #Get exposure results
        isofile = config['model_data']['country_grid']
        expomodel = Exposure(popfile,pop_year,isofile)
        exposure = None
        exposure = expomodel.calcExposure(pargs.gridfile)

        #get fatality results, if requested
        fatmodel = EmpiricalLoss.fromDefaultFatality()
        fatdict = fatmodel.getLosses(exposure)

        #get economic results, if requested
        econexpmodel = EconExposure(popfile,pop_year,isofile)
        ecomodel = EmpiricalLoss.fromDefaultEconomic()
        econexposure = econexpmodel.calcExposure(pargs.gridfile)
        ecodict = ecomodel.getLosses(econexposure)
        shakegrid = econexpmodel.getShakeGrid()

        #Get semi-empirical losses, if requested
        urbanfile = config['model_data']['urban_rural_grid']
        if not os.path.isfile(urbanfile):
            raise PagerException('Urban-rural grid file %s does not exist.' % urbanfile)

        semi = SemiEmpiricalFatality.fromDefault()
        semi.setGlobalFiles(popfile,pop_year,urbanfile,isofile)
        semiloss,resfat,nonresfat = semi.getLosses(pargs.gridfile)

        #get all of the other components of PAGER
        #get the fatality and economic comments
        impact1,impact2 = get_impact_comments(fatdict,ecodict,econexposure,event_year)
        #get comment describing vulnerable structures in the region.
        struct_comment = get_structure_comment(resfat,nonresfat,semi)
        #get the comment describing historic secondary hazards
        secondary_comment = get_secondary_comment(elat,elon,emag)
        #get the comment describing historical comments in the region
        historical_comment = get_historical_comment(elat,elon,emag,exposure,fatdict)

        #generate the probability plots
        fat_probs_file,eco_probs_file = _draw_probs(fatmodel,fatdict,
                                                    ecomodel,ecodict,
                                                    version_folder)

        #generate the exposure map
        exposure_pdf = os.path.join(version_folder,'exposure.pdf')
        oceanfile = config['model_data']['ocean_vectors']
        cityfile = config['model_data']['city_file']
        pngfile,mapcities = draw_contour(pargs.gridfile,popfile,
                                         oceanfile,cityfile,exposure_pdf,
                                         make_png=True)
        
        
        doc = PagerData()
        doc.setInputs(shakegrid,pager_version,shakegrid.getEventDict()['event_id'])
        doc.setExposure(exposure,econexposure)
        doc.setModelResults(fatmodel,ecomodel,
                            fatdict,ecodict,
                            semiloss,resfat,nonresfat)
        doc.setComments(impact1,impact2,struct_comment,historical_comment,secondary_comment)
        doc.setMapInfo(cityfile,mapcities)
        doc.validate()
        json_folder = os.path.join(version_folder,'json')
        os.makedirs(json_folder)
        doc.saveToJSON(json_folder)
    except Exception as e:
        if plog is not None:
            f = io.StringIO()
            traceback.print_exc(file=f)
            msg = errobj
            msg = '%s\n %s' % (str(msg),f.getvalue())
            hostname = socket.gethostname()
            msg = msg + '\n' + 'Error occurred on %s\n' % (hostname)
            if gridfile is not None:
                msg = msg + '\n' + 'Error on file: %s\n' % (gridfile)
            if eventcode is not None:
                msg = msg + '\n' + 'Error on event: %s\n' % (eventcode)
            if vnum is not None:
                msg = msg + '\n' + 'Error on version: %i\n' % (vnum)
            if plog is not None:
                plog.scream(msg)
                plog.stopLogging()
            print('Sent error to email')
            f.close()
        else:
            sys.stderr.write(str(e)+'\n')
            traceback.print_exc()
        sys.exit(1)
if __name__ == '__main__':
    desc = '''Run PAGER loss models and create all PAGER products.

    This program presumes that you have a configuration file in ~/.losspager/config.json,
    consisting of the following entries:

    model_data:
      population_data:
        - population_year: 1998
          population_grid: /Users/user/pager/data/lspop1998.flt
        - population_year: 2011
          population_grid: /Users/user/pager/data/lspop2011.flt
        - population_year: 2012
          population_grid: /Users/user/pager/data/lspop2012.flt
        - population_year: 2013
          population_grid: /Users/user/pager/data/lspop2013.flt


      country_grid: /Users/user/pager/data/isogrid.bil
      urban_rural_grid: /Users/user/pager/data/glurextents.bil

    database:
        url: sqlite:////Users/user/.losspager/losspager_schema.db
    
    
    Example usage:
    %(prog)s grid.xml
    '''
    parser = argparse.ArgumentParser(description=desc,formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('gridfile',
                        help='The path to a ShakeMap grid.xml file')
    parser.add_argument('-d','--debug', action='store_true',
                        default=False, help='Print debug information (mostly useful to developers)')
    parser.add_argument('-i','--eventinfo', action='store_false',
                        default=True, help='Turn off printing of basic event information')
    
    args = parser.parse_args()

    #get config file name, make sure it exists
    configfilename = os.path.join(os.path.expanduser('~'),'.losspager','config.yml')
    if not os.path.isfile(configfilename):
        print('Config file could not be found at %s.  Exiting.\n\n' % configfilename)
        parser.print_help()
        sys.exit(1)

    #parse config file
    config = read_config(configfilename)
    
    #Make sure model_data section exists
    try:
        config['model_data']['population_data'][0]['population_year']
        config['model_data']['population_data'][0]['population_grid']
        os.path.isfile(config['model_data']['country_grid'])
        os.path.isfile(config['model_data']['urban_rural_grid'])
    except:
        errmsg = 'Config file %s is missing some or all of the required information.  See the help for the required format.\n'
        sys.stderr.write(errmsg)
        sys.exit(1)
    
    main(args,config)
